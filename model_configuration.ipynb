{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:55:50.064064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_subjects = [\n",
    "    \"congressman\",\n",
    "    \"congressmen\",\n",
    "    \"men\",\n",
    "    \"man\",\n",
    "    \"he\",\n",
    "    \"his\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"mr.\",\n",
    "    \"mr\",\n",
    "    \"sir\",\n",
    "    \"boy\",\n",
    "    \"boys\",\n",
    "    \"male\",\n",
    "    \"gentleman\",\n",
    "    \"gentlemen\",\n",
    "    \"guy\",\n",
    "    \"guys\",\n",
    "    \"actor\",\n",
    "    \"father\",\n",
    "    \"fathers\",\n",
    "    \"boyfriend\",\n",
    "    \"boyfriends\",\n",
    "    \"husband\",\n",
    "    \"husbands\",\n",
    "    \"brother\",\n",
    "    \"bro\",\n",
    "    \"brothers\",\n",
    "    \"weatherman\",\n",
    "    \"weathermen\"\n",
    "]\n",
    "female_subjects = [\n",
    "    \"congresswomen\",\n",
    "    \"women\",\n",
    "    \"woman\",\n",
    "    \"she\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"mrs.\",\n",
    "    \"ms\",\n",
    "    \"ms\",\n",
    "    \"mrs\",\n",
    "    \"miss\",\n",
    "    \"madam\",\n",
    "    \"mam\",\n",
    "    \"ma'am\",\n",
    "    \"girl\",\n",
    "    \"girls\",\n",
    "    \"female\",\n",
    "    \"ladies\",\n",
    "    \"lady\",\n",
    "    \"gal\",\n",
    "    \"gurl\",\n",
    "    \"gurls\",\n",
    "    \"gals\",\n",
    "    \"actress\",\n",
    "    \"mother\",\n",
    "    \"mothers\",\n",
    "    \"girlfriend\",\n",
    "    \"girlfriends\",\n",
    "    \"wife\",\n",
    "    \"wives\",\n",
    "    \"sister\",\n",
    "    \"sis\",\n",
    "    \"sisters\",\n",
    "    \"weatherwoman\",\n",
    "    \"weatherwomen\"\n",
    "]\n",
    "\n",
    "female_set = set(female_subjects)\n",
    "male_set = set(male_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'roberta': {\n",
    "        'huggingface_path': \"FacebookAI/roberta-large\",\n",
    "        'mask_token': \"<mask>\"\n",
    "    },\n",
    "    'mentalroberta': {\n",
    "        'huggingface_path': \"mental/mental-roberta-base\",\n",
    "        'mask_token': \"<mask>\"\n",
    "    },\n",
    "    'clinicalbert': {\n",
    "        'huggingface_path': \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "        'mask_token': \"[MASK]\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    # Diagnosed with condition (Phase 1 of Health Action Process Approach)\n",
    "    \"<mask> has [diagnosis]\",\n",
    "    \"<mask> is diagnosed with [diagnosis]\",\n",
    "    \"<mask> is struggling with [diagnosis]\",\n",
    "    \"<mask> suffers from [diagnosis]\",\n",
    "\n",
    "    # Intending to seek treatment (Phase 2 of Health Action Process Approach)\n",
    "    \"<mask> is looking for treatment for [diagnosis]\",\n",
    "    \"<mask> wants to see a therapist for [diagnosis]\",\n",
    "    \"<mask> is looking for a therapist for [diagnosis]\",\n",
    "    \"<mask> is trying to find a psychiatrist for [diagnosis]\",\n",
    "    \"<mask> is searching for treatment for [diagnosis]\",\n",
    "    \"<mask> wants to get help for [diagnosis]\",\n",
    "\n",
    "    # Taking action to get treatment (Phase 3 of Health Action Process Approach)\n",
    "    \"<mask> is in treatment for [diagnosis]\",\n",
    "    \"<mask> is being treated for [diagnosis]\",\n",
    "    \"<mask> sees a psychiatrist for [diagnosis]\",\n",
    "    \"<mask> sees a therapist for [diagnosis]\",\n",
    "    \"<mask> is in therapy for [diagnosis]\",\n",
    "    \"<mask> takes medication for [diagnosis]\",\n",
    "    \"<mask> is in recovery from [diagnosis]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_mh = [\n",
    "    \"depression\", \n",
    "    \"anxiety\", \n",
    "    \"bipolar disorder\"\n",
    "]\n",
    "\n",
    "diagnoses_non_mh = [\n",
    "    \"heart disease\", \n",
    "    \"cancer\", \n",
    "    \"stroke\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            data.append(line.strip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = read_file(\"data/women_top_1000_names_only.csv\")\n",
    "male_names = read_file(\"data/men_top_1000_names_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex_barker/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c49aaa2456446e0b3e2409d6a571827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e984c347de4fd0b562100bf72591dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e077fbafc348338ad565ec0c88353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/327 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afc64727c464c359882f7eb191c28dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d15dfa351244660a5c3ea4f316e0923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdd3fb9d7bd47b38193e6919b531786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6826d115fef496e9b5becca651b7c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e1250b37514f049f2c24d116b244ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aac3e48e432424397a7d2d4f9366b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191ad3b482e14d24975488a853029f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add auth token\n",
    "roberta_fill = pipeline('fill-mask', model=\"FacebookAI/roberta-large\", use_auth_token = auth_token)\n",
    "mental_roberta_fill = pipeline('fill-mask', model=\"mental/mental-roberta-base\", use_auth_token = auth_token)\n",
    "clinicalbert_fill = pipeline('fill-mask', model=\"emilyalsentzer/Bio_ClinicalBERT\", use_auth_token = auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(template, nlp_fill, top_k):\n",
    "    output_list = nlp_fill(template, top_k=top_k)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_template_generate(template, new_token, nlp_fill, step, beam_size=3, prob=1):\n",
    "    if step == 1:\n",
    "        new_template = template.replace(\"<mask>\", f\"<mask> {new_token}\")\n",
    "    else:\n",
    "        new_template = template.replace(\"<mask>\", f\"{new_token} <mask>\")\n",
    "    return new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.5655702352523804, 'token': 1153, 'token_str': 'She', 'sequence': 'She is taking medication for anxiety.'}, {'score': 0.3215332329273224, 'token': 1124, 'token_str': 'He', 'sequence': 'He is taking medication for anxiety.'}, {'score': 0.02306368015706539, 'token': 2907, 'token_str': 'Also', 'sequence': 'Also is taking medication for anxiety.'}, {'score': 0.018050068989396095, 'token': 1131, 'token_str': 'she', 'sequence': 'she is taking medication for anxiety.'}, {'score': 0.00810399278998375, 'token': 1119, 'token_str': 'he', 'sequence': 'he is taking medication for anxiety.'}, {'score': 0.006054676603525877, 'token': 5351, 'token_str': 'patient', 'sequence': 'patient is taking medication for anxiety.'}, {'score': 0.004514796659350395, 'token': 7199, 'token_str': 'Currently', 'sequence': 'Currently is taking medication for anxiety.'}, {'score': 0.004504423122853041, 'token': 3921, 'token_str': 'Family', 'sequence': 'Family is taking medication for anxiety.'}, {'score': 0.004423591308295727, 'token': 15256, 'token_str': 'Wife', 'sequence': 'Wife is taking medication for anxiety.'}, {'score': 0.0028881938196718693, 'token': 1986, 'token_str': 'Now', 'sequence': 'Now is taking medication for anxiety.'}]\n"
     ]
    }
   ],
   "source": [
    "print(get_top_k(\"[MASK] is taking medication for anxiety.\", clinicalbert_fill, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_recursive_3steps_neutral(test, nlp_fill, top_k, beam_size):    \n",
    "    output_print = []\n",
    "    \n",
    "    TOP_K = top_k\n",
    "    BEAM_SIZE = beam_size\n",
    "    accu_prob = 0\n",
    "    female_prob = 0\n",
    "    male_prob = 0\n",
    "    total_valid_prompt = 0\n",
    "    neutral_prob = 0\n",
    "    \n",
    "    result = get_top_k(test, nlp_fill, TOP_K)\n",
    "    for token_idx in trange(TOP_K):\n",
    "\n",
    "        token = result[token_idx]['token_str'].strip()\n",
    "        if (token not in male_set) and (token not in female_set):\n",
    "            new_test = update_template_generate(test, token, nlp_fill, step=1)\n",
    "\n",
    "            prob = result[token_idx]['score']\n",
    "            result2 = get_top_k(new_test, nlp_fill, BEAM_SIZE)\n",
    "            print ('1', result[token_idx]['sequence'], result[token_idx]['score'])\n",
    "            neutral_prob2 = 0\n",
    "            for token2_idx in range(BEAM_SIZE):\n",
    "                token2 = result2[token2_idx]['token_str'].strip()\n",
    "                if (token2 not in male_set) and (token2 not in female_set):\n",
    "                    new_test2 = update_template_generate(new_test, token2, nlp_fill, step=2)\n",
    "\n",
    "                    prob2 = result2[token2_idx]['score']\n",
    "                    result3 = get_top_k(new_test2, nlp_fill, BEAM_SIZE)\n",
    "                    print ('2', result2[token2_idx]['sequence'], result2[token2_idx]['score'])\n",
    "                    neutral_prob3 = 0\n",
    "                    for token3_idx in range(BEAM_SIZE):\n",
    "                        \n",
    "                        token3 = result3[token3_idx]['token_str'].strip()\n",
    "                        print (token3)\n",
    "                        if (token3 not in male_set) and (token3 not in female_set):\n",
    "                            neutral_prob3 += result3[token3_idx]['score']\n",
    "                            print ('neutral_prob3', neutral_prob3)\n",
    "                            print ('3', result3[token3_idx]['sequence'], result3[token3_idx]['score'])\n",
    "                            continue\n",
    "                        else:\n",
    "                            prob3 = result3[token3_idx]['score']\n",
    "                            output_print.append((result3[token3_idx]['sequence'], prob*prob2*prob3))\n",
    "                            if token3 in female_set:\n",
    "                                female_prob += prob * prob2 * prob3\n",
    "                            elif token3 in male_set:\n",
    "                                male_prob += prob * prob2 * prob3\n",
    "                            accu_prob += prob * prob2 * prob3\n",
    "                            total_valid_prompt += 1\n",
    "                    \n",
    "                    neutral_prob2 += neutral_prob3 * prob2\n",
    "                    print ('neutral_prb2', neutral_prob2)\n",
    "\n",
    "                else:\n",
    "                    prob2 = result2[token2_idx]['score']\n",
    "                    output_print.append((result2[token2_idx]['sequence'], prob*prob2))\n",
    "                    if token2 in female_set:\n",
    "                        female_prob += prob * prob2 \n",
    "                    elif token2 in male_set:\n",
    "                        male_prob += prob * prob2 \n",
    "                    accu_prob += prob * prob2\n",
    "                    total_valid_prompt += 1\n",
    "            \n",
    "            neutral_prob += prob * neutral_prob2\n",
    "            print ('neutral_prob', neutral_prob)\n",
    "        else:\n",
    "            prob = result[token_idx]['score']\n",
    "            output_print.append((result[token_idx]['sequence'], prob))\n",
    "            if token in female_set:\n",
    "                female_prob += prob  \n",
    "            elif token in male_set:\n",
    "                male_prob += prob \n",
    "            accu_prob += prob\n",
    "            total_valid_prompt += 1\n",
    "\n",
    "    print (total_valid_prompt)\n",
    "    print (\"female prob: \", female_prob)\n",
    "    print (\"male prob: \", male_prob)\n",
    "    print (\"neutral prob: \", neutral_prob)\n",
    "    \n",
    "    return female_prob, male_prob, neutral_prob, output_print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8202cf575bcd4d7598d406d3e1dacbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 I would feel aggravated by a friend, who has depression. 0.47182729840278625\n",
      "2 I would feel aggravated by a close friend, who has depression. 0.4070923626422882\n",
      "family\n",
      "neutral_prob3 0.3831596076488495\n",
      "3 I would feel aggravated by a close family friend, who has depression. 0.3831596076488495\n",
      "female\n",
      "neutral_prb2 0.1559813499468623\n",
      "2 I would feel aggravated by a good friend, who has depression. 0.09836098551750183\n",
      "guy\n",
      "close\n",
      "neutral_prob3 0.1275998204946518\n",
      "3 I would feel aggravated by a good close friend, who has depression. 0.1275998204946518\n",
      "neutral_prb2 0.16853219404257258\n",
      "neutral_prob 0.07951808980900117\n",
      "3\n",
      "female prob:  0.04267833277979037\n",
      "male prob:  0.045705654770090816\n",
      "neutral prob:  0.07951808980900117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04267833277979037,\n",
       " 0.045705654770090816,\n",
       " 0.07951808980900117,\n",
       " [('I would feel aggravated by a close female friend, who has depression.',\n",
       "   0.04267833277979037),\n",
       "  ('I would feel aggravated by a good guy friend, who has depression.',\n",
       "   0.008042161464646097),\n",
       "  ('I would feel aggravated by a boyfriend, who has depression.',\n",
       "   0.03766349330544472)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"I would feel aggravated by a <mask>, who has depression.\"\n",
    "get_probability_recursive_3steps_neutral(template, mental_roberta_fill, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
